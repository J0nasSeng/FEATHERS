{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/automl/lib/python3.9/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: libc10_cuda.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from opacus import PrivacyEngine\n",
    "import torch.nn.functional as F\n",
    "from operations import *\n",
    "from genotypes import PRIMITIVES\n",
    "from genotypes import Genotype\n",
    "from opacus.grad_sample import GradSampleModule, register_grad_sampler\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "from typing import Dict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding sample-wise Gradients for Supernet\n",
    "\n",
    "In this notebook we derive how we come up with sample-wise gradients for our supernet we use to perform differentiable NAS. For this we note that the supernet is based on a convex, weighted combination of operations which are all applied to the same input, that is each _mixed operation_ is defined as follows:\n",
    "\\begin{equation}\n",
    "    m = \\sum_{o \\in O} \\alpha_o \\cdot o(x)\n",
    "\\end{equation}\n",
    "Each $o$ is a convolution/pooling operation or a regular neural network, thus opacus already knows how to compute sample-based gradients for all parameters of each $o$. Thus, with a smart design of our supernet-architecture we can avoid the computation of sample-wise gradients for all the operations we have in use and pass the heavy lifting to opacus. The problem then reduces to providing opacus with sample-wise gradients w.r.t $\\alpha_o$ for each $o$.\n",
    "\n",
    "For this, let's see how we compute the gradients of an arbitrary loss w.r.t. the alpha-parameters in a simple setup: We only have 3 operations, each associated with a certaing weight $\\alpha_o$. The mixed operation is then followed by a linear transformation producing the output, thus the network reads:\n",
    "\\begin{equation}\n",
    "    \\hat{y} = \\bigg(\\sum_{o \\in O} \\alpha_o \\cdot o(x) \\bigg) \\cdot \\mathbf{W}\n",
    "\\end{equation}\n",
    "\n",
    "The following shwos the forward pass of such a network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [torch.randn(1, 5) for _ in range(0, 4)]\n",
    "alphas = nn.Parameter(torch.ones(4) / 4, requires_grad=True)\n",
    "W = nn.Parameter(torch.randn(5, 1), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2500, 0.2500, 0.2500, 0.2500], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmaxed_alphas = torch.softmax(alphas, dim=0)\n",
    "softmaxed_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1655]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mop = sum(alphas[i] * X[i] for i in range(0, 4))\n",
    "y = torch.matmul(mop, W)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's proceed with computing a loss and updating the parameters. To keep things easy, let's pretend our loss is just the sum of all elements in our output. We then can compute the gradients w.r.t. each $\\alpha_o$ easily by calling the backward-method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.5030,  3.3426, -0.0513,  2.8738])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = torch.sum(y)\n",
    "l.backward()\n",
    "alphas.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient can be expressed as follows:\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial \\ell}{\\partial \\alpha_o} = \\sum_{i=1}^n \\frac{\\partial \\ell}{\\partial z^{(0)}_k} \\cdot \\frac{\\partial z^{(0)}_k}{\\partial \\alpha_o}\n",
    "\\end{equation}\n",
    "Here we sum over all gradients of our $n$ outputs w.r.t. $\\alpha_o$. $z^{(0)}_k$ denotes the $k$-th element of the last layer (output). Expanding this further yields:\n",
    "\\begin{align}\n",
    "    \\frac{\\partial \\ell}{\\partial \\alpha_o} = & \\sum_{i=1}^n \\frac{\\partial \\ell}{\\partial z^{(0)}_k} \\cdot \\sum_{d=1}^{|L_1|} \\mathbf{W}^{(1)}_{d k} \\cdot \\frac{\\partial z_d^{(1)}}{\\partial \\alpha_o} \\\\\n",
    "    & \\sum_{i=1}^n \\frac{\\partial \\ell}{\\partial z^{(0)}_k} \\cdot \\sum_{d=1}^{|L_1|} \\mathbf{W}^{(1)}_{d k} \\cdot \\frac{\\partial \\sum_{o \\in O} \\big( \\alpha_o o(z^{(2)}) \\big)}{\\partial \\alpha_o} \\\\\n",
    "    &  \\sum_{i=1}^n \\frac{\\partial \\ell}{\\partial z^{(0)}_k} \\cdot \\sum_{d=1}^{|L_1|} \\mathbf{W}^{(1)}_{d k} \\cdot o(z^{(2)})_d\n",
    "\\end{align}\n",
    "Since $\\frac{\\partial \\ell}{\\partial z^{(0)}_k} = 1$ we obtain:\n",
    "\\begin{align}\n",
    "    \\frac{\\partial \\ell}{\\partial \\alpha_o} & = \\sum_{k=1}^n \\sum_{d=1}^{|L_1|} \\mathbf{W}_{d k}^{(1)} \\cdot o(z^{(2)})_d \\\\\n",
    "\\end{align}\n",
    "This reduces to:\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial \\ell}{\\partial \\alpha_o} = \\sum_{k=1}^n \\big(\\mathbf{W}^{(1)^T}\\big)_k \\cdot o(z^{(2)})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5030],\n",
       "        [ 3.3426],\n",
       "        [-0.0513],\n",
       "        [ 2.8738]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.cat(X, dim=0)\n",
    "1 * X.matmul(W) # 1 = derivative w.r.t. the output of mixed operation, rest as derived above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending the Minimal Example\n",
    "Now we will start extending the above approach. As you can see computing the gradients and deriving the forumlas can get cumbersome really quickly. That's why we should use opacus' capabilities of computing sample-wise gradients for as many modules as possible. Below we define 3 operations that will be used withing our NAS-approach. For these modules opacus already knows how to compute sample-wise gradients, thus we can just go ahead and use them as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Op1(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, h_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "class Op2(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, h_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "class Op3(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, h_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "PRIMS = [Op1, Op2, Op3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tricky part is the mixed operation-module. If we would use plain pytorch, we just could go ahead and build one `MixedOp` module taking care of calling each operation and compute the convex combination of the operation's output. However, since opacus does not know the MixedOp-module it cannot compute the sample-wise gradients w.r.t. the alpha-parameters. Thus we have to tell opacus how to compute the gradients. For this opacus provides the activations (input to our module) and the gradients w.r.t. the outputs of our module. If we would go for a \"plain-pytorch approach\" this would require us to compute the gradients w.r.t. alpha-parameters and the model-parameters of each operation \"by hand\". Since this is cumbersome and not error-prone, we split up the MixedOp into two parts: One `ParallelOp` which does nothing but applying each operation on the same input data and a `MixedOp` (please don't get confused by the naming) which just cares about computing the convex combination of the oerpation's output computed by the ParallelOp. \n",
    "\n",
    "This way we can compute the gradients w.r.t. the alphas easily by just applying the same reasoning as above. The gradients can then be computed by computing the vector-product of the activations and the gradients w.r.t. the MixedOp (which are both provided by opacus). Mathematically this can be expressed as follows assuming we have an $n \\times i$-dimensional real activation matrix $\\mathbf{a}$ and an $i$-dimensional real vector $\\nabla \\mathbf{m}$ representing the gradients w.r.t. our mixed operation. We have an activation of $n \\times i$ because we compute the convex combination of $n$ operations, each producing outputs of dimension $i$. Since each of the $n$ operations is associated with a weight $\\alpha_j$, we aim to compute the gradient w.r.t. each of the $n$ weights, thus we aim to obtain a $n$-dimensional gradient vector for one sample and a $B \\times n$-dimensional gradient matrix for a batch of size $B$. We can easily compute this using an einsum:\n",
    "\\begin{equation}\n",
    "    \\nabla_{j} \\alpha_m = \\sum_{k=1}^i \\nabla \\mathbf{m}_i \\cdot \\mathbf{a}_{m k}\n",
    "\\end{equation}\n",
    "Here $\\nabla_j \\alpha_m$ is the $j$-th element of the gradient vector w.r.t. to the alphas associated with operation $m$. As we can see this is just a more general version of the equation we've derived above.\n",
    "\n",
    "But this is not all we have to do: Remember we have the ParallelOp computing all the operation's outputs. This module does not have any parameters, thus there is nothing we can update and so there are also no gradients for this module. Thus we can tell opacus that there is nothing to compute in the backward pass. Details on the implementation can be obtained below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelOp(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, h_dim, out_dim) -> None:\n",
    "        super(ParallelOp, self).__init__()\n",
    "        self._ops = nn.ModuleList()\n",
    "        for primitive in PRIMS:\n",
    "            self._ops.append(primitive(in_dim, h_dim, out_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        operation_outs = []\n",
    "        for op in self._ops:\n",
    "            out = op(x)\n",
    "            operation_outs.append(out)\n",
    "        return torch.stack(operation_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedOp(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MixedOp, self).__init__()\n",
    "        self.alphas = nn.Parameter(torch.zeros(len(PRIMS)), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weights = torch.softmax(self.alphas, 0)\n",
    "        return sum(w * op_out for w, op_out in zip(weights, x))\n",
    "\n",
    "    def arch_params(self):\n",
    "        return [self.alphas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, hdim, out_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, hdim)\n",
    "        self.fc2 = nn.Linear(hdim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.hstack(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'in_dim', 'hdim', and 'out_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jonas/dev/automl/HANF/hanf_dp/dp_supernet_derivation.ipynb Cell 16\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jonas/dev/automl/HANF/hanf_dp/dp_supernet_derivation.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mixed_op \u001b[39m=\u001b[39m MixedOp()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jonas/dev/automl/HANF/hanf_dp/dp_supernet_derivation.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m net \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(ParallelOp(\u001b[39m28\u001b[39m\u001b[39m*\u001b[39m\u001b[39m28\u001b[39m, \u001b[39m512\u001b[39m, \u001b[39m256\u001b[39m), mixed_op, LastLayer())\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jonas/dev/automl/HANF/hanf_dp/dp_supernet_derivation.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m optim \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(mixed_op\u001b[39m.\u001b[39march_params(), \u001b[39m0.01\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jonas/dev/automl/HANF/hanf_dp/dp_supernet_derivation.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'in_dim', 'hdim', and 'out_dim'"
     ]
    }
   ],
   "source": [
    "mixed_op = MixedOp()\n",
    "net = nn.Sequential(ParallelOp(28*28, 512, 256), mixed_op, LastLayer())\n",
    "optim = torch.optim.SGD(mixed_op.arch_params(), 0.01)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0,), (1,))])\n",
    "train_data = torchvision.datasets.FashionMNIST('../../datasets/femnist/', download=True, train=True, transform=transform)\n",
    "val_data = torchvision.datasets.FashionMNIST('../../datasets/femnist/', download=True, train=False, transform=transform)\n",
    "train_loader = DataLoader(train_data, 64)\n",
    "val_loader = DataLoader(val_data, 64)\n",
    "\n",
    "@register_grad_sampler(ParallelOp)\n",
    "def grad_sampler_parallel_op(layer: MixedOp, activations: torch.Tensor, backprops: torch.Tensor):\n",
    "    return {}\n",
    "\n",
    "@register_grad_sampler(MixedOp)\n",
    "def grad_sampler_mixed_op(layer: MixedOp, activations: torch.Tensor, backprops: torch.Tensor):\n",
    "    grad = torch.einsum('nbi,bi->nb', activations, backprops)\n",
    "    ret = {\n",
    "        layer.alphas: grad\n",
    "    }\n",
    "    return ret\n",
    "\n",
    "pe = PrivacyEngine()\n",
    "netc = deepcopy(net)\n",
    "net_, optim_, train_loader_ = pe.make_private(module=net, optimizer=optim, data_loader=train_loader, noise_multiplier=1., max_grad_norm=1.)\n",
    "x_first, y_first = next(iter(train_loader_))\n",
    "x_first = x_first.reshape((x_first.shape[0], 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_first = torch.randn((64, 784))\n",
    "y_first = torch.ones(64, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'netc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jonas/dev/automl/HANF/hanf_dp/dp_supernet_derivation.ipynb Cell 18\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jonas/dev/automl/HANF/hanf_dp/dp_supernet_derivation.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m pnetc, pnet_ \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(netc\u001b[39m.\u001b[39mparameters(), net_\u001b[39m.\u001b[39mparameters()):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jonas/dev/automl/HANF/hanf_dp/dp_supernet_derivation.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mall(pnet_\u001b[39m.\u001b[39mdata \u001b[39m==\u001b[39m pnetc\u001b[39m.\u001b[39mdata))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'netc' is not defined"
     ]
    }
   ],
   "source": [
    "for pnetc, pnet_ in zip(netc.parameters(), net_.parameters()):\n",
    "    print(torch.all(pnet_.data == pnetc.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/automl/lib/python3.9/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    }
   ],
   "source": [
    "y_pred = net_(x_first)\n",
    "l = loss(y_pred, y_first)\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = netc(x_first)\n",
    "l = loss(y_pred, y_first)\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "for pnetc, pnet_ in zip(netc.parameters(), net_.parameters()):\n",
    "    print(torch.all(pnetc.grad.data == pnet_.grad.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: Does this make sense? \n",
    "> \n",
    "> Yes it does since the optimizer performs the clipping and adds noise, thus the gradients are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building up a Cell\n",
    "Now that we know how to build MixedOps with minimal effort, we can use the MixedOps in order to build up cells and we will use the cells in turn to build up our architecture search space. Since cells don't introduce any additional parameters, building a cell based on a set of MixedOps shoud be straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell(nn.Module):\n",
    "    # TODO: Do the same as above and check that gradients are correct!\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.nodes = nn.ModuleList()\n",
    "        # initialize stem modules with some conv-operation self.stem0, self.stem1 = \n",
    "        curr_in_dim = 28*28\n",
    "        curr_hdim = int(0.75 * curr_in_dim)\n",
    "        curr_out_dim = int(0.75 * curr_hdim)\n",
    "        dims = [curr_out_dim]\n",
    "        for i in range(5):\n",
    "            if i == 0:\n",
    "                mop = nn.Sequential(ParallelOp(curr_in_dim, curr_hdim, curr_out_dim), MixedOp())\n",
    "            else:\n",
    "                in_dim = sum(dims)\n",
    "                hdim = int(0.75*in_dim)\n",
    "                out_dim = int(0.75*hdim)\n",
    "                dims.append(out_dim)\n",
    "                mop = nn.Sequential(ParallelOp(in_dim, hdim, out_dim), MixedOp())\n",
    "            self.nodes.append(mop)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        inp = [self.nodes[0](x)]\n",
    "        for op in self.nodes[1:]:\n",
    "            print(torch.hstack(inp).shape)\n",
    "            out = op(torch.hstack(inp))\n",
    "            inp.append(out)\n",
    "        \n",
    "        return inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Supernet\n",
    "Now that we know how to build up a cell we can proceed and glue several cells to one network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.cell1 = Cell()\n",
    "        self.linear1 = nn.Linear(2623, 28*28)\n",
    "        self.cell2 = Cell()\n",
    "        self.out = LastLayer(2623, 256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cell1(x)\n",
    "        x = torch.hstack(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.cell2(x)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(net: nn.Module, param_type='arch'):\n",
    "    parameters = []\n",
    "    for name, param in net.named_parameters():\n",
    "        if param_type == 'arch':\n",
    "            if 'alphas' in name:\n",
    "                parameters.append(param)\n",
    "        elif param_type == 'model':\n",
    "            if 'alphas' not in name:\n",
    "                parameters.append(param)\n",
    "        else:\n",
    "            raise ValueError('Unsupported parameter type, must be either arch or model')\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/automl/lib/python3.9/site-packages/opacus/privacy_engine.py:130: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#net = nn.Sequential(Cell(), LastLayer(2623, 256, 10))\n",
    "net = Network()\n",
    "params = get_params(net, 'arch')\n",
    "optim = torch.optim.SGD(params, 0.01)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0,), (1,))])\n",
    "train_data = torchvision.datasets.FashionMNIST('../../datasets/femnist/', download=True, train=True, transform=transform)\n",
    "val_data = torchvision.datasets.FashionMNIST('../../datasets/femnist/', download=True, train=False, transform=transform)\n",
    "train_loader = DataLoader(train_data, 64)\n",
    "val_loader = DataLoader(val_data, 64)\n",
    "\n",
    "@register_grad_sampler(ParallelOp)\n",
    "def grad_sampler_parallel_op(layer: MixedOp, activations: torch.Tensor, backprops: torch.Tensor):\n",
    "    return {}\n",
    "\n",
    "@register_grad_sampler(MixedOp)\n",
    "def grad_sampler_mixed_op(layer: MixedOp, activations: torch.Tensor, backprops: torch.Tensor):\n",
    "    grad = torch.einsum('nbi,bi->nb', activations, backprops)\n",
    "    ret = {\n",
    "        layer.alphas: grad\n",
    "    }\n",
    "    return ret\n",
    "\n",
    "pe = PrivacyEngine()\n",
    "netc = deepcopy(net)\n",
    "net_, optim_, train_loader_ = pe.make_private(module=net, optimizer=optim, data_loader=train_loader, noise_multiplier=1., max_grad_norm=1.)\n",
    "x_first, y_first = next(iter(train_loader_))\n",
    "x_first = x_first.reshape((x_first.shape[0], 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_first = torch.randn((64, 784))\n",
    "y_first = torch.ones(64, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/automl/lib/python3.9/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 441])\n",
      "torch.Size([64, 688])\n",
      "torch.Size([64, 1075])\n",
      "torch.Size([64, 1679])\n",
      "torch.Size([64, 441])\n",
      "torch.Size([64, 688])\n",
      "torch.Size([64, 1075])\n",
      "torch.Size([64, 1679])\n",
      "torch.Size([64, 441])\n",
      "torch.Size([64, 688])\n",
      "torch.Size([64, 1075])\n",
      "torch.Size([64, 1679])\n",
      "torch.Size([64, 441])\n",
      "torch.Size([64, 688])\n",
      "torch.Size([64, 1075])\n",
      "torch.Size([64, 1679])\n"
     ]
    }
   ],
   "source": [
    "y_pred = net_(x_first)\n",
    "l = loss(y_pred, y_first)\n",
    "l.backward()\n",
    "\n",
    "y_pred = netc(x_first)\n",
    "l = loss(y_pred, y_first)\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "for pnetc, pnet_ in zip(netc.parameters(), net_.parameters()):\n",
    "    print(torch.all(pnetc.grad.data == pnet_.grad.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer to CNNs\n",
    "In the above example we have used standard MLPs as our operations. However, our ultimate goal is to perform image classification, thus our operation-space consists of convolution- and pooling-operations. This requires us to adapt the computation of the gradients slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedOp(nn.Module):\n",
    "\n",
    "  def __init__(self, C, stride):\n",
    "    super(MixedOp, self).__init__()\n",
    "    self._ops = nn.ModuleList()\n",
    "    for primitive in PRIMITIVES:\n",
    "      op = OPS[primitive](C, stride, False)\n",
    "      if 'pool' in primitive:\n",
    "        op = nn.Sequential(op, nn.GroupNorm(num_groups=1, num_channels=C, affine=False))\n",
    "      self._ops.append(op)\n",
    "\n",
    "  def forward(self, x, weights):\n",
    "    return sum(w * op(x) for w, op in zip(weights, self._ops))\n",
    "\n",
    "\n",
    "class Cell(nn.Module):\n",
    "\n",
    "  def __init__(self, steps, multiplier, C_prev_prev, C_prev, C, reduction, reduction_prev):\n",
    "    super(Cell, self).__init__()\n",
    "    self.reduction = reduction\n",
    "\n",
    "    if reduction_prev:\n",
    "      self.preprocess0 = FactorizedReduce(C_prev_prev, C, affine=False)\n",
    "    else:\n",
    "      self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 0, affine=False)\n",
    "    self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 0, affine=False)\n",
    "    self._steps = steps\n",
    "    self._multiplier = multiplier\n",
    "\n",
    "    self._ops = nn.ModuleList()\n",
    "    self._bns = nn.ModuleList()\n",
    "    for i in range(self._steps):\n",
    "      for j in range(2+i):\n",
    "        stride = 2 if reduction and j < 2 else 1\n",
    "        op = MixedOp(C, stride)\n",
    "        self._ops.append(op)\n",
    "\n",
    "  def forward(self, s0, s1, weights):\n",
    "    s0 = self.preprocess0(s0)\n",
    "    s1 = self.preprocess1(s1)\n",
    "\n",
    "    states = [s0, s1]\n",
    "    offset = 0\n",
    "    for i in range(self._steps):\n",
    "      s = sum(self._ops[offset+j](h, weights[offset+j]) for j, h in enumerate(states))\n",
    "      offset += len(states)\n",
    "      states.append(s)\n",
    "\n",
    "    return torch.cat(states[-self._multiplier:], dim=1)\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "\n",
    "  def __init__(self, C, num_classes, layers, criterion, device, in_channels=3, steps=4, multiplier=4, stem_multiplier=3):\n",
    "    super(Network, self).__init__()\n",
    "    self._C = C\n",
    "    self._num_classes = num_classes\n",
    "    self._layers = layers\n",
    "    self._criterion = criterion\n",
    "    self._steps = steps\n",
    "    self._multiplier = multiplier\n",
    "    self.device = device\n",
    "\n",
    "    C_curr = stem_multiplier*C\n",
    "    self.stem = nn.Sequential(\n",
    "      nn.Conv2d(in_channels, C_curr, 3, padding=1, bias=False),\n",
    "      nn.GroupNorm(num_groups=1, num_channels=C_curr),\n",
    "    )\n",
    " \n",
    "    C_prev_prev, C_prev, C_curr = C_curr, C_curr, C\n",
    "    self.cells = nn.ModuleList()\n",
    "    reduction_prev = False\n",
    "    for i in range(layers):\n",
    "      if i in [layers//3, 2*layers//3]:\n",
    "        C_curr *= 2\n",
    "        reduction = True\n",
    "      else:\n",
    "        reduction = False\n",
    "      cell = Cell(steps, multiplier, C_prev_prev, C_prev, C_curr, reduction, reduction_prev)\n",
    "      reduction_prev = reduction\n",
    "      self.cells += [cell]\n",
    "      C_prev_prev, C_prev = C_prev, multiplier*C_curr\n",
    "\n",
    "    self.global_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "    self.classifier = nn.Linear(C_prev, num_classes)\n",
    "\n",
    "    self._initialize_alphas()\n",
    "\n",
    "  def new(self):\n",
    "    model_new = Network(self._C, self._num_classes, self._layers, self._criterion, self.device).to(self.device)\n",
    "    for x, y in zip(model_new.arch_parameters(), self.arch_parameters()):\n",
    "        x.data.copy_(y.data)\n",
    "    return model_new\n",
    "\n",
    "  def forward(self, input):\n",
    "    s0 = s1 = self.stem(input)\n",
    "    for i, cell in enumerate(self.cells):\n",
    "      if cell.reduction:\n",
    "        weights = F.softmax(self.alphas_reduce, dim=-1)\n",
    "      else:\n",
    "        weights = F.softmax(self.alphas_normal, dim=-1)\n",
    "      s0, s1 = s1, cell(s0, s1, weights)\n",
    "    out = self.global_pooling(s1)\n",
    "    logits = self.classifier(out.view(out.size(0),-1))\n",
    "    return logits\n",
    "\n",
    "  def _initialize_alphas(self):\n",
    "    k = sum(1 for i in range(self._steps) for n in range(2+i))\n",
    "    num_ops = len(PRIMITIVES)\n",
    "\n",
    "    self.alphas_normal = nn.Parameter(1e-3*torch.zeros((k, num_ops)).to(self.device), requires_grad=True)\n",
    "    self.alphas_reduce = nn.Parameter(1e-3*torch.zeros((k, num_ops)).to(self.device), requires_grad=True)\n",
    "    self._arch_parameters = [\n",
    "      self.alphas_normal,\n",
    "      self.alphas_reduce,\n",
    "    ]\n",
    "\n",
    "  def arch_parameters(self):\n",
    "    return self._arch_parameters\n",
    "\n",
    "  def genotype(self):\n",
    "\n",
    "    def _parse(weights):\n",
    "      gene = []\n",
    "      n = 2\n",
    "      start = 0\n",
    "      for i in range(self._steps):\n",
    "        end = start + n\n",
    "        W = weights[start:end].copy()\n",
    "        edges = sorted(range(i + 2), key=lambda x: -max(W[x][k] for k in range(len(W[x])) if k != PRIMITIVES.index('none')))[:2]\n",
    "        for j in edges:\n",
    "          k_best = None\n",
    "          for k in range(len(W[j])):\n",
    "            if k != PRIMITIVES.index('none'):\n",
    "              if k_best is None or W[j][k] > W[j][k_best]:\n",
    "                k_best = k\n",
    "          gene.append((PRIMITIVES[k_best], j))\n",
    "        start = end\n",
    "        n += 1\n",
    "      return gene\n",
    "\n",
    "    gene_normal = _parse(F.softmax(self.alphas_normal, dim=-1).data.cpu().numpy())\n",
    "    gene_reduce = _parse(F.softmax(self.alphas_reduce, dim=-1).data.cpu().numpy())\n",
    "\n",
    "    concat = range(2+self._steps-self._multiplier, self._steps+2)\n",
    "    genotype = Genotype(\n",
    "      normal=gene_normal, normal_concat=concat,\n",
    "      reduce=gene_reduce, reduce_concat=concat\n",
    "    )\n",
    "    return genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cpu')\n",
    "model = Network(16, 10, 4, criterion, device, in_channels=1) # Cell(4, 3, 16, 36, 48, False, False)\n",
    "optim_arch = torch.optim.SGD(get_params(model, 'arch'), 0.01)\n",
    "optim_model = torch.optim.SGD(get_params(model, 'model'), 0.01)\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0,), (1,))])\n",
    "train_data = torchvision.datasets.FashionMNIST('../../datasets/femnist/', download=True, train=True, transform=transform)\n",
    "val_data = torchvision.datasets.FashionMNIST('../../datasets/femnist/', download=True, train=False, transform=transform)\n",
    "train_loader = DataLoader(train_data, 64)\n",
    "val_loader = DataLoader(val_data, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# initialize all weights to zero\n",
    "for param in get_params(model, 'model'):\n",
    "    param.data.fill_(0.1)\n",
    "\n",
    "for param in get_params(model, 'model'):\n",
    "    print(torch.all(param.data == 0.1))\n",
    "\n",
    "for param in get_params(model, 'arch'):\n",
    "    print(torch.all(param.data == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelOp(nn.Module):\n",
    "\n",
    "  def __init__(self, C, stride) -> None:\n",
    "    super().__init__()\n",
    "    self._ops = nn.ModuleList()\n",
    "    for primitive in PRIMITIVES:\n",
    "      op = OPS[primitive](C, stride, False)\n",
    "      if 'pool' in primitive:\n",
    "        op = nn.Sequential(op, nn.GroupNorm(num_groups=1, num_channels=C, affine=False))\n",
    "      self._ops.append(op)\n",
    "\n",
    "  def forward(self, x):\n",
    "      operation_outs = []\n",
    "      for op in self._ops:\n",
    "          out = op(x)\n",
    "          operation_outs.append(out)\n",
    "      return torch.stack(operation_outs)\n",
    "\n",
    "class MixedOp(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MixedOp, self).__init__()\n",
    "        self.alphas = nn.Parameter(torch.zeros(len(PRIMITIVES)), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "      weights = torch.softmax(self.alphas, 0)\n",
    "      return sum(w * op_out for w, op_out in zip(weights, x))\n",
    "\n",
    "\n",
    "class Cell(nn.Module):\n",
    "\n",
    "  def __init__(self, steps, multiplier, C_prev_prev, C_prev, C, reduction, reduction_prev, mixed_ops_normal, mixed_ops_reduce):\n",
    "    super(Cell, self).__init__()\n",
    "    self.reduction = reduction\n",
    "\n",
    "    if reduction_prev:\n",
    "      self.preprocess0 = FactorizedReduce(C_prev_prev, C, affine=False)\n",
    "    else:\n",
    "      self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 0, affine=False)\n",
    "    self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 0, affine=False)\n",
    "    self._steps = steps\n",
    "    self._multiplier = multiplier\n",
    "\n",
    "    self._ops = nn.ModuleList()\n",
    "    self._bns = nn.ModuleList()\n",
    "\n",
    "    mixed_op_idx = 0\n",
    "    for i in range(self._steps):\n",
    "      for j in range(2+i):\n",
    "        stride = 2 if reduction and j < 2 else 1\n",
    "        if reduction:\n",
    "          op = nn.Sequential(ParallelOp(C, stride), mixed_ops_reduce[mixed_op_idx])\n",
    "        else:\n",
    "          op = nn.Sequential(ParallelOp(C, stride), mixed_ops_normal[mixed_op_idx])\n",
    "        mixed_op_idx += 1\n",
    "        self._ops.append(op)\n",
    "\n",
    "  def forward(self, s0, s1):\n",
    "    s0 = self.preprocess0(s0)\n",
    "    s1 = self.preprocess1(s1)\n",
    "\n",
    "    states = [s0, s1]\n",
    "    offset = 0\n",
    "    for i in range(self._steps):\n",
    "      s = sum(self._ops[offset+j](h) for j, h in enumerate(states))\n",
    "      offset += len(states)\n",
    "      states.append(s)\n",
    "\n",
    "    return torch.cat(states[-self._multiplier:], dim=1)\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "\n",
    "  def __init__(self, C, num_classes, layers, criterion, device, in_channels=3, steps=4, multiplier=4, stem_multiplier=3):\n",
    "    super(Network, self).__init__()\n",
    "    self._C = C\n",
    "    self._num_classes = num_classes\n",
    "    self._layers = layers\n",
    "    self._criterion = criterion\n",
    "    self._steps = steps\n",
    "    self._multiplier = multiplier\n",
    "    self.device = device\n",
    "\n",
    "    C_curr = stem_multiplier*C\n",
    "    self.stem = nn.Sequential(\n",
    "      nn.Conv2d(in_channels, C_curr, 3, padding=1, bias=False),\n",
    "      nn.GroupNorm(num_groups=1, num_channels=C_curr),\n",
    "    )\n",
    " \n",
    "    C_prev_prev, C_prev, C_curr = C_curr, C_curr, C\n",
    "    self.cells = nn.ModuleList()\n",
    "    reduction_prev = False\n",
    "    self._init_mixed_ops()\n",
    "    for i in range(layers):\n",
    "      if i in [layers//3, 2*layers//3]:\n",
    "        C_curr *= 2\n",
    "        reduction = True\n",
    "      else:\n",
    "        reduction = False\n",
    "\n",
    "      cell = Cell(steps, multiplier, C_prev_prev, C_prev, C_curr, reduction, reduction_prev, self.mixed_ops_normal, self.mixed_ops_reduce)\n",
    "      reduction_prev = reduction\n",
    "      self.cells += [cell]\n",
    "      C_prev_prev, C_prev = C_prev, multiplier*C_curr\n",
    "\n",
    "    self.global_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "    self.classifier = nn.Linear(C_prev, num_classes)\n",
    "\n",
    "  def new(self):\n",
    "    model_new = Network(self._C, self._num_classes, self._layers, self._criterion, self.device).to(self.device)\n",
    "    for x, y in zip(get_params(model_new, 'arch'), get_params(self, 'arch')):\n",
    "        x.data.copy_(y.data)\n",
    "    return model_new\n",
    "\n",
    "  def forward(self, input):\n",
    "    s0 = s1 = self.stem(input)\n",
    "    for i, cell in enumerate(self.cells):\n",
    "      s0, s1 = s1, cell(s0, s1)\n",
    "    out = self.global_pooling(s1)\n",
    "    logits = self.classifier(out.view(out.size(0),-1))\n",
    "    return logits\n",
    "\n",
    "  def _init_mixed_ops(self):\n",
    "    k = sum(1 for i in range(self._steps) for n in range(2+i))\n",
    "    self.mixed_ops_normal = [MixedOp() for _ in range(k)]\n",
    "    self.mixed_ops_reduce = [MixedOp() for _ in range(k)]\n",
    "\n",
    "  def genotype(self):\n",
    "\n",
    "    def _parse(weights):\n",
    "      gene = []\n",
    "      n = 2\n",
    "      start = 0\n",
    "      for i in range(self._steps):\n",
    "        end = start + n\n",
    "        W = weights[start:end].copy()\n",
    "        edges = sorted(range(i + 2), key=lambda x: -max(W[x][k] for k in range(len(W[x])) if k != PRIMITIVES.index('none')))[:2]\n",
    "        for j in edges:\n",
    "          k_best = None\n",
    "          for k in range(len(W[j])):\n",
    "            if k != PRIMITIVES.index('none'):\n",
    "              if k_best is None or W[j][k] > W[j][k_best]:\n",
    "                k_best = k\n",
    "          gene.append((PRIMITIVES[k_best], j))\n",
    "        start = end\n",
    "        n += 1\n",
    "      return gene\n",
    "\n",
    "    alphas_normal = torch.stack([mop.alphas.data for mop in self.mixed_ops_normal])\n",
    "    alphas_reduce = torch.stack([mop.alphas.data for mop in self.mixed_ops_reduce])\n",
    "    gene_normal = _parse(F.softmax(alphas_normal, dim=-1).data.cpu().numpy())\n",
    "    gene_reduce = _parse(F.softmax(alphas_reduce, dim=-1).data.cpu().numpy())\n",
    "\n",
    "    concat = range(2+self._steps-self._multiplier, self._steps+2)\n",
    "    genotype = Genotype(\n",
    "      normal=gene_normal, normal_concat=concat,\n",
    "      reduce=gene_reduce, reduce_concat=concat\n",
    "    )\n",
    "    return genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flat_grad_sample(p: torch.Tensor):\n",
    "    if p.grad_sample is None:\n",
    "        raise ValueError(\n",
    "            \"Per sample gradient is not initialized. Not updated in backward pass?\"\n",
    "        )\n",
    "    if isinstance(p.grad_sample, torch.Tensor):\n",
    "        ret = p.grad_sample\n",
    "    elif isinstance(p.grad_sample, list):\n",
    "        ret = torch.cat(p.grad_sample, dim=0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected grad_sample type: {type(p.grad_sample)}\")\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/automl/lib/python3.9/site-packages/opacus/privacy_engine.py:130: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@register_grad_sampler(ParallelOp)\n",
    "def grad_sampler_parallel_op(layer: MixedOp, activations: torch.Tensor, backprops: torch.Tensor):\n",
    "    return {}\n",
    "\n",
    "@register_grad_sampler(MixedOp)\n",
    "def grad_sampler_mixed_op(layer: MixedOp, activations: torch.Tensor, backprops: torch.Tensor):\n",
    "    sftmx = torch.softmax(layer.alphas, 0)\n",
    "    j_sftmx_vals = []\n",
    "    for i in range(len(sftmx)):\n",
    "        col = []\n",
    "        for j in range(len(sftmx)):\n",
    "            if i == j:\n",
    "                deriv = sftmx[i] * (1 - sftmx[i])\n",
    "            else:\n",
    "                deriv = -sftmx[j] * sftmx[i]\n",
    "            col.append(deriv)\n",
    "        j_sftmx_vals.append(col)\n",
    "    j_sftmx_trans = torch.tensor(j_sftmx_vals)\n",
    "    \n",
    "    #print(torch.all(activations[0] == 0))\n",
    "    # d = c = number of operations, b = number of batches\n",
    "    sftmx_grad = torch.einsum('dc,cb...->db...', j_sftmx_trans, activations) # we sum over columns since we have the transposed jacobian of softmax w.r.t. inputs\n",
    "    final_grad = torch.einsum('db...,b...->db', sftmx_grad, backprops)\n",
    "    #grad = torch.einsum('nbcwh,bcwh->nb', activations, backprops)\n",
    "    ret = {\n",
    "        layer.alphas: final_grad\n",
    "    }\n",
    "    return ret\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cpu')\n",
    "model_dp = Network(16, 10, 4, criterion, device, in_channels=1) # Cell(4, 3, 16, 36, 48, False, False)\n",
    "optim_arch = torch.optim.SGD(get_params(model_dp, 'arch'), 0.01)\n",
    "optim_model = torch.optim.SGD(get_params(model_dp, 'model'), 0.01)\n",
    "pe = PrivacyEngine()\n",
    "train_loader_c = deepcopy(train_loader)\n",
    "model_dp_, optim_, train_loader_ = pe.make_private(module=model_dp, optimizer=optim_arch, data_loader=train_loader_c, noise_multiplier=1., max_grad_norm=1.)\n",
    "x_first, y_first = next(iter(train_loader_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# initialize all weights to zero\n",
    "for param in get_params(model_dp_, 'model'):\n",
    "    param.data.fill_(0.1)\n",
    "\n",
    "for param in get_params(model_dp_, 'model'):\n",
    "    print(torch.all(param.data == 0.1))\n",
    "\n",
    "for param in get_params(model_dp_, 'arch'):\n",
    "    print(torch.all(param.data == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "y_pred1= model(x_first)\n",
    "l = criterion(y_pred1, y_first)\n",
    "l.backward()\n",
    "\n",
    "y_pred2 = model_dp_(x_first)\n",
    "l = criterion(y_pred2, y_first)\n",
    "l.backward()\n",
    "\n",
    "print(torch.all(y_pred1 == y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_normal_dp = []\n",
    "params_reduce_dp = []\n",
    "alpahs_dp_model = [param for name, param in model_dp_.named_parameters() if 'alpha' in name]\n",
    "for i, param in enumerate(alpahs_dp_model):\n",
    "    # the first 14 entries refer to normal cell's alphas\n",
    "    if i < 14:\n",
    "        params_normal_dp.append(param)\n",
    "    else:\n",
    "        params_reduce_dp.append(param)\n",
    "\n",
    "dp_arch_normal_params_grads = [param.grad.data for param in params_normal_dp]\n",
    "dp_arch_reduce_params_grads = [param.grad.data for param in params_reduce_dp]\n",
    "dp_arch_normal_params_grads = torch.stack(dp_arch_normal_params_grads)\n",
    "dp_arch_reduce_params_grads = torch.stack(dp_arch_reduce_params_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_normal_orig = []\n",
    "params_reduce_orig = []\n",
    "alpahs_dp_model = [param for name, param in model_dp_.named_parameters() if 'alpha' in name]\n",
    "for i, param in enumerate(alpahs_dp_model):\n",
    "    # the first 14 entries refer to normal cell's alphas\n",
    "    if i < 14:\n",
    "        params_normal_orig.append(param)\n",
    "    else:\n",
    "        params_reduce_orig.append(param)\n",
    "\n",
    "orig_arch_normal_params_grads = [param.grad.data for param in params_normal_orig]\n",
    "orig_arch_reduce_params_grads = [param.grad.data for param in params_reduce_orig]\n",
    "orig_arch_normal_params_grads = torch.stack(orig_arch_normal_params_grads)\n",
    "orig_arch_reduce_params_grads = torch.stack(orig_arch_reduce_params_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(orig_arch_normal_params_grads == dp_arch_normal_params_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(orig_arch_reduce_params_grads == dp_arch_reduce_params_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = [param.grad.data for name, param in model.named_parameters() if 'alpha' not in name]\n",
    "model_dp_params = [param.grad.data for name, param in model_dp_.named_parameters() if 'alpha' not in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# since the naming of the parameters is not aligned in the original model and the dp-model, \n",
    "# we take the classifier gradients as proxy to check if the model's gradients are the same in both models\n",
    "classifier_weights, classifier_bias = None, None\n",
    "for name, param in model.named_parameters():\n",
    "    if name == 'classifier.weight':\n",
    "        classifier_weights = param\n",
    "    elif name == 'classifier.bias':\n",
    "        classifier_bias = param\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "equals = []\n",
    "for name, param in model_dp_.named_parameters():\n",
    "    if name == '_module.classifier.weight':\n",
    "        is_equal = torch.all(classifier_weights.grad.data == param.grad.data)\n",
    "        equals.append(is_equal.item())\n",
    "    elif name == '.module.classifier.bias':\n",
    "        is_equal = torch.all(classifier_bias.grad.data == param.grad.data)\n",
    "        equals.append(is_equal.item())\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(all(equals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing optimizer-step issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List, Dict, Optional, Callable\n",
    "from opacus.optimizers.utils import params\n",
    "\n",
    "def _mark_as_processed(obj: Union[torch.Tensor, List[torch.Tensor]]):\n",
    "    \"\"\"\n",
    "    Marks parameters that have already been used in the optimizer step.\n",
    "    DP-SGD puts certain restrictions on how gradients can be accumulated. In particular,\n",
    "    no gradient can be used twice - client must call .zero_grad() between\n",
    "    optimizer steps, otherwise privacy guarantees are compromised.\n",
    "    This method marks tensors that have already been used in optimizer steps to then\n",
    "    check if zero_grad has been duly called.\n",
    "    Notes:\n",
    "          This is used to only mark ``p.grad_sample`` and ``p.summed_grad``\n",
    "    Args:\n",
    "        obj: tensor or a list of tensors to be marked\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        obj._processed = True\n",
    "    elif isinstance(obj, list):\n",
    "        for x in obj:\n",
    "            x._processed = True\n",
    "\n",
    "\n",
    "def _check_processed_flag_tensor(x: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Checks if this gradient tensor has been previously used in optimization step.\n",
    "    See Also:\n",
    "        :meth:`~opacus.optimizers.optimizer._mark_as_processed`\n",
    "    Args:\n",
    "        x: gradient tensor\n",
    "    Raises:\n",
    "        ValueError\n",
    "            If tensor has attribute ``._processed`` previously set by\n",
    "            ``_mark_as_processed`` method\n",
    "    \"\"\"\n",
    "\n",
    "    if hasattr(x, \"_processed\"):\n",
    "        raise ValueError(\n",
    "            \"Gradients haven't been cleared since the last optimizer step. \"\n",
    "            \"In order to obtain privacy guarantees you must call optimizer.zero_grad()\"\n",
    "            \"on each step\"\n",
    "        )\n",
    "\n",
    "\n",
    "def _check_processed_flag(obj: Union[torch.Tensor, List[torch.Tensor]]):\n",
    "    \"\"\"\n",
    "    Checks if this gradient tensor (or a list of tensors) has been previously\n",
    "    used in optimization step.\n",
    "    See Also:\n",
    "        :meth:`~opacus.optimizers.optimizer._mark_as_processed`\n",
    "    Args:\n",
    "        x: gradient tensor or a list of tensors\n",
    "    Raises:\n",
    "        ValueError\n",
    "            If tensor (or at least one tensor from the list) has attribute\n",
    "            ``._processed`` previously set by ``_mark_as_processed`` method\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        _check_processed_flag_tensor(obj)\n",
    "    elif isinstance(obj, list):\n",
    "        for x in obj:\n",
    "            _check_processed_flag_tensor(x)\n",
    "\n",
    "\n",
    "def _generate_noise(\n",
    "    std: float,\n",
    "    reference: torch.Tensor,\n",
    "    generator=None,\n",
    "    secure_mode: bool = False,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generates noise according to a Gaussian distribution with mean 0\n",
    "    Args:\n",
    "        std: Standard deviation of the noise\n",
    "        reference: The reference Tensor to get the appropriate shape and device\n",
    "            for generating the noise\n",
    "        generator: The PyTorch noise generator\n",
    "        secure_mode: boolean showing if \"secure\" noise need to be generated\n",
    "            (see the notes)\n",
    "    Notes:\n",
    "        If `secure_mode` is enabled, the generated noise is also secure\n",
    "        against the floating point representation attacks, such as the ones\n",
    "        in https://arxiv.org/abs/2107.10138 and https://arxiv.org/abs/2112.05307.\n",
    "        The attack for Opacus first appeared in https://arxiv.org/abs/2112.05307.\n",
    "        The implemented fix is based on https://arxiv.org/abs/2107.10138 and is\n",
    "        achieved through calling the Gaussian noise function 2*n times, when n=2\n",
    "        (see section 5.1 in https://arxiv.org/abs/2107.10138).\n",
    "        Reason for choosing n=2: n can be any number > 1. The bigger, the more\n",
    "        computation needs to be done (`2n` Gaussian samples will be generated).\n",
    "        The reason we chose `n=2` is that, `n=1` could be easy to break and `n>2`\n",
    "        is not really necessary. The complexity of the attack is `2^p(2n-1)`.\n",
    "        In PyTorch, `p=53` and so complexity is `2^53(2n-1)`. With `n=1`, we get\n",
    "        `2^53` (easy to break) but with `n=2`, we get `2^159`, which is hard\n",
    "        enough for an attacker to break.\n",
    "    \"\"\"\n",
    "    zeros = torch.zeros(reference.shape, device=reference.device)\n",
    "    if std == 0:\n",
    "        return zeros\n",
    "    # TODO: handle device transfers: generator and reference tensor\n",
    "    # could be on different devices\n",
    "    if secure_mode:\n",
    "        torch.normal(\n",
    "            mean=0,\n",
    "            std=std,\n",
    "            size=(1, 1),\n",
    "            device=reference.device,\n",
    "            generator=generator,\n",
    "        )  # generate, but throw away first generated Gaussian sample\n",
    "        sum = zeros\n",
    "        for _ in range(4):\n",
    "            sum += torch.normal(\n",
    "                mean=0,\n",
    "                std=std,\n",
    "                size=reference.shape,\n",
    "                device=reference.device,\n",
    "                generator=generator,\n",
    "            )\n",
    "        return sum / 2\n",
    "    else:\n",
    "        return torch.normal(\n",
    "            mean=0,\n",
    "            std=std,\n",
    "            size=reference.shape,\n",
    "            device=reference.device,\n",
    "            generator=generator,\n",
    "        )\n",
    "\n",
    "class DPOptimizer(torch.optim.Optimizer):\n",
    "    \"\"\"\n",
    "    ``torch.optim.Optimizer`` wrapper that adds additional functionality to clip per\n",
    "    sample gradients and add Gaussian noise.\n",
    "    Can be used with any ``torch.optim.Optimizer`` subclass as an underlying optimizer.\n",
    "    ``DPOptimzer`` assumes that parameters over which it performs optimization belong\n",
    "    to GradSampleModule and therefore have the ``grad_sample`` attribute.\n",
    "    On a high level ``DPOptimizer``'s step looks like this:\n",
    "    1) Aggregate ``p.grad_sample`` over all parameters to calculate per sample norms\n",
    "    2) Clip ``p.grad_sample`` so that per sample norm is not above threshold\n",
    "    3) Aggregate clipped per sample gradients into ``p.grad``\n",
    "    4) Add Gaussian noise to ``p.grad`` calibrated to a given noise multiplier and\n",
    "    max grad norm limit (``std = noise_multiplier * max_grad_norm``).\n",
    "    5) Call underlying optimizer to perform optimization step\n",
    "    Examples:\n",
    "        >>> module = MyCustomModel()\n",
    "        >>> optimizer = torch.optim.SGD(module.parameters(), lr=0.1)\n",
    "        >>> dp_optimizer = DPOptimizer(\n",
    "        ...     optimizer=optimizer,\n",
    "        ...     noise_multiplier=1.0,\n",
    "        ...     max_grad_norm=1.0,\n",
    "        ...     expected_batch_size=4,\n",
    "        ... )\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        *,\n",
    "        noise_multiplier: float,\n",
    "        max_grad_norm: float,\n",
    "        expected_batch_size: Optional[int],\n",
    "        loss_reduction: str = \"mean\",\n",
    "        generator=None,\n",
    "        secure_mode: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            optimizer: wrapped optimizer.\n",
    "            noise_multiplier: noise multiplier\n",
    "            max_grad_norm: max grad norm used for gradient clipping\n",
    "            expected_batch_size: batch_size used for averaging gradients. When using\n",
    "                Poisson sampling averaging denominator can't be inferred from the\n",
    "                actual batch size. Required is ``loss_reduction=\"mean\"``, ignored if\n",
    "                ``loss_reduction=\"sum\"``\n",
    "            loss_reduction: Indicates if the loss reduction (for aggregating the gradients)\n",
    "                is a sum or a mean operation. Can take values \"sum\" or \"mean\"\n",
    "            generator: torch.Generator() object used as a source of randomness for\n",
    "                the noise\n",
    "            secure_mode: if ``True`` uses noise generation approach robust to floating\n",
    "                point arithmetic attacks.\n",
    "                See :meth:`~opacus.optimizers.optimizer._generate_noise` for details\n",
    "        \"\"\"\n",
    "        if loss_reduction not in (\"mean\", \"sum\"):\n",
    "            raise ValueError(f\"Unexpected value for loss_reduction: {loss_reduction}\")\n",
    "\n",
    "        if loss_reduction == \"mean\" and expected_batch_size is None:\n",
    "            raise ValueError(\n",
    "                \"You must provide expected batch size of the loss reduction is mean\"\n",
    "            )\n",
    "\n",
    "        self.original_optimizer = optimizer\n",
    "        self.noise_multiplier = noise_multiplier\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        self.loss_reduction = loss_reduction\n",
    "        self.expected_batch_size = expected_batch_size\n",
    "        self.step_hook = None\n",
    "        self.generator = generator\n",
    "        self.secure_mode = secure_mode\n",
    "\n",
    "        self.param_groups = self.original_optimizer.param_groups\n",
    "        self.defaults = self.original_optimizer.defaults\n",
    "        self.state = self.original_optimizer.state\n",
    "        self._step_skip_queue = []\n",
    "        self._is_last_step_skipped = False\n",
    "\n",
    "        for p in self.params:\n",
    "            p.summed_grad = None\n",
    "\n",
    "    def _get_flat_grad_sample(self, p: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Return parameter's per sample gradients as a single tensor.\n",
    "        By default, per sample gradients (``p.grad_sample``) are stored as one tensor per\n",
    "        batch basis. Therefore, ``p.grad_sample`` is a single tensor if holds results from\n",
    "        only one batch, and a list of tensors if gradients are accumulated over multiple\n",
    "        steps. This is done to provide visibility into which sample belongs to which batch,\n",
    "        and how many batches have been processed.\n",
    "        This method returns per sample gradients as a single concatenated tensor, regardless\n",
    "        of how many batches have been accumulated\n",
    "        Args:\n",
    "            p: Parameter tensor. Must have ``grad_sample`` attribute\n",
    "        Returns:\n",
    "            ``p.grad_sample`` if it's a tensor already, or a single tensor computed by\n",
    "            concatenating every tensor in ``p.grad_sample`` if it's a list\n",
    "        Raises:\n",
    "            ValueError\n",
    "                If ``p`` is missing ``grad_sample`` attribute\n",
    "        \"\"\"\n",
    "\n",
    "        if not hasattr(p, \"grad_sample\"):\n",
    "            raise ValueError(\n",
    "                \"Per sample gradient not found. Are you using GradSampleModule?\"\n",
    "            )\n",
    "        if p.grad_sample is None:\n",
    "            raise ValueError(\n",
    "                \"Per sample gradient is not initialized. Not updated in backward pass?\"\n",
    "            )\n",
    "        if isinstance(p.grad_sample, torch.Tensor):\n",
    "            ret = p.grad_sample\n",
    "        elif isinstance(p.grad_sample, list):\n",
    "            ret = torch.cat(p.grad_sample, dim=0)\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected grad_sample type: {type(p.grad_sample)}\")\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def signal_skip_step(self, do_skip=True):\n",
    "        \"\"\"\n",
    "        Signals the optimizer to skip an optimization step and only perform clipping and\n",
    "        per sample gradient accumulation.\n",
    "        On every call of ``.step()`` optimizer will check the queue of skipped step\n",
    "        signals. If non-empty and the latest flag is ``True``, optimizer will call\n",
    "        ``self.clip_and_accumulate``, but won't proceed to adding noise and performing\n",
    "        the actual optimization step.\n",
    "        It also affects the behaviour of ``zero_grad()``. If the last step was skipped,\n",
    "        optimizer will clear per sample gradients accumulated by\n",
    "        ``self.clip_and_accumulate`` (``p.grad_sample``), but won't touch aggregated\n",
    "        clipped gradients (``p.summed_grad``)\n",
    "        Used by :class:`~opacus.utils.batch_memory_manager.BatchMemoryManager` to\n",
    "        simulate large virtual batches with limited memory footprint.\n",
    "        Args:\n",
    "            do_skip: flag if next step should be skipped\n",
    "        \"\"\"\n",
    "        self._step_skip_queue.append(do_skip)\n",
    "\n",
    "    def _check_skip_next_step(self, pop_next=True):\n",
    "        \"\"\"\n",
    "        Checks if next step should be skipped by the optimizer.\n",
    "        This is for large Poisson batches that get split into smaller physical batches\n",
    "        to fit on the device. Batches that do not correspond to the end of a Poisson\n",
    "        batch or thus `skipped` as their gradient gets accumulated for one big step.\n",
    "        \"\"\"\n",
    "        if self._step_skip_queue:\n",
    "            if pop_next:\n",
    "                return self._step_skip_queue.pop(0)\n",
    "            else:\n",
    "                return self._step_skip_queue[0]\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    @property\n",
    "    def params(self) -> List[nn.Parameter]:\n",
    "        \"\"\"\n",
    "        Returns a flat list of ``nn.Parameter`` managed by the optimizer\n",
    "        \"\"\"\n",
    "        return params(self)\n",
    "\n",
    "    @property\n",
    "    def grad_samples(self) -> List[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Returns a flat list of per sample gradient tensors (one per parameter)\n",
    "        \"\"\"\n",
    "        ret = []\n",
    "        for p in self.params:\n",
    "            ret.append(self._get_flat_grad_sample(p))\n",
    "        return ret\n",
    "\n",
    "    @property\n",
    "    def accumulated_iterations(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns number of batches currently accumulated and not yet processed.\n",
    "        In other words ``accumulated_iterations`` tracks the number of forward/backward\n",
    "        passed done in between two optimizer steps. The value would typically be 1,\n",
    "        but there are possible exceptions.\n",
    "        Used by privacy accountants to calculate real sampling rate.\n",
    "        \"\"\"\n",
    "        vals = []\n",
    "        for p in self.params:\n",
    "            if not hasattr(p, \"grad_sample\"):\n",
    "                raise ValueError(\n",
    "                    \"Per sample gradient not found. Are you using GradSampleModule?\"\n",
    "                )\n",
    "            if isinstance(p.grad_sample, torch.Tensor):\n",
    "                vals.append(1)\n",
    "            elif isinstance(p.grad_sample, list):\n",
    "                vals.append(len(p.grad_sample))\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected grad_sample type: {type(p.grad_sample)}\")\n",
    "\n",
    "        if len(set(vals)) > 1:\n",
    "            raise ValueError(\n",
    "                \"Number of accumulated steps is inconsistent across parameters\"\n",
    "            )\n",
    "        return vals[0]\n",
    "\n",
    "    def attach_step_hook(self, fn):\n",
    "        \"\"\"\n",
    "        Attaches a hook to be executed after gradient clipping/noising, but before the\n",
    "        actual optimization step.\n",
    "        Most commonly used for privacy accounting.\n",
    "        Args:\n",
    "            fn: hook function. Expected signature: ``foo(optim: DPOptimizer)``\n",
    "        \"\"\"\n",
    "\n",
    "        self.step_hook = fn\n",
    "\n",
    "    def clip_and_accumulate(self):\n",
    "        \"\"\"\n",
    "        Performs gradient clipping.\n",
    "        Stores clipped and aggregated gradients into `p.summed_grad```\n",
    "        \"\"\"\n",
    "\n",
    "        trans_grad_samples = [g.transpose(0, 1) for g in self.grad_samples]\n",
    "        per_param_norms = [\n",
    "            g.reshape(len(g), -1).norm(2, dim=-1) for g in trans_grad_samples\n",
    "        ]\n",
    "        per_sample_norms = torch.stack(per_param_norms, dim=1).norm(2, dim=1)\n",
    "        per_sample_clip_factor = (self.max_grad_norm / (per_sample_norms + 1e-6)).clamp(\n",
    "            max=1.0\n",
    "        )\n",
    "\n",
    "        for p in self.params:\n",
    "            _check_processed_flag(p.grad_sample)\n",
    "            grad_sample = self._get_flat_grad_sample(p)\n",
    "            grad = torch.sum(grad_sample * per_sample_clip_factor, dim=1)\n",
    "\n",
    "            if p.summed_grad is not None:\n",
    "                p.summed_grad += grad\n",
    "            else:\n",
    "                p.summed_grad = grad\n",
    "\n",
    "            _mark_as_processed(p.grad_sample)\n",
    "\n",
    "    def add_noise(self):\n",
    "        \"\"\"\n",
    "        Adds noise to clipped gradients. Stores clipped and noised result in ``p.grad``\n",
    "        \"\"\"\n",
    "\n",
    "        for p in self.params:\n",
    "            _check_processed_flag(p.summed_grad)\n",
    "\n",
    "            noise = _generate_noise(\n",
    "                std=self.noise_multiplier * self.max_grad_norm,\n",
    "                reference=p.summed_grad,\n",
    "                generator=self.generator,\n",
    "                secure_mode=self.secure_mode,\n",
    "            )\n",
    "            p.grad = (p.summed_grad + noise).view_as(p)\n",
    "\n",
    "            _mark_as_processed(p.summed_grad)\n",
    "\n",
    "    def scale_grad(self):\n",
    "        \"\"\"\n",
    "        Applies given ``loss_reduction`` to ``p.grad``.\n",
    "        Does nothing if ``loss_reduction=\"sum\"``. Divides gradients by\n",
    "        ``self.expected_batch_size`` if ``loss_reduction=\"mean\"``\n",
    "        \"\"\"\n",
    "        if self.loss_reduction == \"mean\":\n",
    "            for p in self.params:\n",
    "                p.grad /= self.expected_batch_size * self.accumulated_iterations\n",
    "\n",
    "    def zero_grad(self, set_to_none: bool = False):\n",
    "        \"\"\"\n",
    "        Clear gradients.\n",
    "        Clears ``p.grad``, ``p.grad_sample`` and ``p.summed_grad`` for all of it's parameters\n",
    "        Notes:\n",
    "            ``set_to_none`` argument only affects ``p.grad``. ``p.grad_sample`` and\n",
    "            ``p.summed_grad`` is never zeroed out and always set to None.\n",
    "            Normal grads can do this, because their shape is always the same.\n",
    "            Grad samples do not behave like this, as we accumulate gradients from different\n",
    "            batches in a list\n",
    "        Args:\n",
    "            set_to_none: instead of setting to zero, set the grads to None. (only\n",
    "            affects regular gradients. Per sample gradients are always set to None)\n",
    "        \"\"\"\n",
    "\n",
    "        for p in self.params:\n",
    "            p.grad_sample = None\n",
    "\n",
    "            if not self._is_last_step_skipped:\n",
    "                p.summed_grad = None\n",
    "\n",
    "        self.original_optimizer.zero_grad(set_to_none)\n",
    "\n",
    "    def pre_step(\n",
    "        self, closure: Optional[Callable[[], float]] = None\n",
    "    ) -> Optional[float]:\n",
    "        \"\"\"\n",
    "        Perform actions specific to ``DPOptimizer`` before calling\n",
    "        underlying  ``optimizer.step()``\n",
    "        Args:\n",
    "            closure: A closure that reevaluates the model and\n",
    "                returns the loss. Optional for most optimizers.\n",
    "        \"\"\"\n",
    "        self.clip_and_accumulate()\n",
    "        if self._check_skip_next_step():\n",
    "            self._is_last_step_skipped = True\n",
    "            return False\n",
    "\n",
    "        self.add_noise()\n",
    "        self.scale_grad()\n",
    "\n",
    "        if self.step_hook:\n",
    "            self.step_hook(self)\n",
    "\n",
    "        self._is_last_step_skipped = False\n",
    "        return True\n",
    "\n",
    "    def step(self, closure: Optional[Callable[[], float]] = None) -> Optional[float]:\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                closure()\n",
    "\n",
    "        if self.pre_step():\n",
    "            return self.original_optimizer.step()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.original_optimizer.__repr__()\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.original_optimizer.state_dict()\n",
    "\n",
    "    def load_state_dict(self, state_dict) -> None:\n",
    "        self.original_optimizer.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/automl/lib/python3.9/site-packages/opacus/privacy_engine.py:130: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@register_grad_sampler(ParallelOp)\n",
    "def grad_sampler_parallel_op(layer: MixedOp, activations: torch.Tensor, backprops: torch.Tensor):\n",
    "    return {}\n",
    "\n",
    "@register_grad_sampler(MixedOp)\n",
    "def grad_sampler_mixed_op(layer: MixedOp, activations: torch.Tensor, backprops: torch.Tensor):\n",
    "    sftmx = torch.softmax(layer.alphas, 0)\n",
    "    j_sftmx_vals = []\n",
    "    for i in range(len(sftmx)):\n",
    "        col = []\n",
    "        for j in range(len(sftmx)):\n",
    "            if i == j:\n",
    "                deriv = sftmx[i] * (1 - sftmx[i])\n",
    "            else:\n",
    "                deriv = -sftmx[j] * sftmx[i]\n",
    "            col.append(deriv)\n",
    "        j_sftmx_vals.append(col)\n",
    "    j_sftmx_trans = torch.tensor(j_sftmx_vals)\n",
    "    \n",
    "    #print(torch.all(activations[0] == 0))\n",
    "    # d = c = number of operations, b = number of batches\n",
    "    sftmx_grad = torch.einsum('dc,cb...->db...', j_sftmx_trans, activations) # we sum over columns since we have the transposed jacobian of softmax w.r.t. inputs\n",
    "    final_grad = torch.einsum('db...,b...->db', sftmx_grad, backprops)\n",
    "    #grad = torch.einsum('nbcwh,bcwh->nb', activations, backprops)\n",
    "    ret = {\n",
    "        layer.alphas: final_grad\n",
    "    }\n",
    "    return ret\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cpu')\n",
    "model_dp = Network(16, 10, 4, criterion, device, in_channels=1) # Cell(4, 3, 16, 36, 48, False, False)\n",
    "optim_arch = torch.optim.SGD(get_params(model_dp, 'arch'), 0.01)\n",
    "optim_model = torch.optim.SGD(get_params(model_dp, 'model'), 0.01)\n",
    "pe = PrivacyEngine()\n",
    "train_loader_c = deepcopy(train_loader)\n",
    "model_dp_, _, train_loader_ = pe.make_private(module=model_dp, optimizer=optim_arch, data_loader=train_loader_c, noise_multiplier=1., max_grad_norm=1.)\n",
    "optim_ = DPOptimizer(optim_arch, noise_multiplier=1., max_grad_norm=1., expected_batch_size=64)\n",
    "x_first, y_first = next(iter(train_loader_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/automl/lib/python3.9/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    }
   ],
   "source": [
    "arch_params_before = [deepcopy(p) for n, p in model_dp_.named_parameters() if 'alpha' in n]\n",
    "optim_.zero_grad()\n",
    "y_hat = model_dp_(x_first)\n",
    "l = criterion(y_hat, y_first)\n",
    "l.backward()\n",
    "arch_params_update = [deepcopy(p) for n, p in model_dp_.named_parameters() if 'alpha' in n]\n",
    "optim_.step()\n",
    "arch_params_after = [deepcopy(p) for n, p in model_dp_.named_parameters() if 'alpha' in n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "for p1, p2 in zip(arch_params_after, arch_params_before):\n",
    "    print(torch.all(p1.data == p2.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch_params_before[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 6.0219e-05,  1.1829e-05,  1.3796e-04, -4.2296e-05,  1.5666e-04,\n",
       "         2.0267e-05,  2.0030e-05, -8.0712e-05], requires_grad=True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch_params_after[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('automl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7613325ebbb1f9384bc508bcd9660c9ee63eceea61e5a048c9a384ab1815eea9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
